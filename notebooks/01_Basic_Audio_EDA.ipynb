{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Audio Exploratory Data Analysis\n",
    "\n",
    "This notebook demonstrates how to perform basic exploratory data analysis on audio files using the CTC-SpeechRefinement package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the project root to the Python path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import Audio, display\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Import from the project\n",
    "from ctc_speech_refinement.core.preprocessing.audio import load_audio\n",
    "from ctc_speech_refinement.core.eda.descriptive_stats import analyze_descriptive_stats\n",
    "from ctc_speech_refinement.core.eda.time_domain import analyze_time_domain\n",
    "from ctc_speech_refinement.core.eda.frequency_domain import analyze_frequency_domain\n",
    "from ctc_speech_refinement.core.eda.pitch_timbre import analyze_pitch_timbre\n",
    "from ctc_speech_refinement.core.eda.anomaly_detection import analyze_anomalies\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Audio Data\n",
    "\n",
    "Let's load an audio file and examine its basic properties using our package's load_audio function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to an audio file\n",
    "audio_file = \"../data/speech2text/input/test1_01.wav\"  # Path to the audio file\n",
    "\n",
    "# Load the audio file using our package's function\n",
    "audio_data, sample_rate = load_audio(audio_file)\n",
    "\n",
    "# Print basic information\n",
    "print(f\"Audio file: {audio_file}\")\n",
    "print(f\"Sample rate: {sample_rate} Hz\")\n",
    "print(f\"Duration: {len(audio_data) / sample_rate:.2f} seconds\")\n",
    "print(f\"Number of samples: {len(audio_data)}\")\n",
    "\n",
    "# Play the audio\n",
    "display(Audio(audio_data, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics Analysis\n",
    "\n",
    "Let's use our package's analyze_descriptive_stats function to compute and visualize descriptive statistics of the audio data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our package's function to analyze descriptive statistics\n",
    "descriptive_stats_results = analyze_descriptive_stats(audio_data, sample_rate, title_prefix=\"Sample Audio\")\n",
    "\n",
    "# Display the statistics\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "for stat, value in descriptive_stats_results['stats'].items():\n",
    "    print(f\"{stat}: {value}\")\n",
    "\n",
    "# Display the figures\n",
    "for fig_name, fig in descriptive_stats_results['figures'].items():\n",
    "    plt.figure(fig.number)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Domain Analysis\n",
    "\n",
    "Let's use our package's analyze_time_domain function to analyze the audio in the time domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our package's function to analyze time domain features\n",
    "time_domain_results = analyze_time_domain(audio_data, sample_rate, title_prefix=\"Sample Audio\")\n",
    "\n",
    "# Display the figures\n",
    "for fig_name, fig in time_domain_results['figures'].items():\n",
    "    plt.figure(fig.number)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Domain Analysis\n",
    "\n",
    "Let's use our package's analyze_frequency_domain function to analyze the audio in the frequency domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our package's function to analyze frequency domain features\n",
    "frequency_domain_results = analyze_frequency_domain(audio_data, sample_rate, title_prefix=\"Sample Audio\")\n",
    "\n",
    "# Display the figures\n",
    "for fig_name, fig in frequency_domain_results['figures'].items():\n",
    "    plt.figure(fig.number)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitch and Timbre Analysis\n",
    "\n",
    "Let's use our package's analyze_pitch_timbre function to analyze the pitch and timbre characteristics of the audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our package's function to analyze pitch and timbre features\n",
    "pitch_timbre_results = analyze_pitch_timbre(audio_data, sample_rate, title_prefix=\"Sample Audio\")\n",
    "\n",
    "# Display the figures\n",
    "for fig_name, fig in pitch_timbre_results['figures'].items():\n",
    "    plt.figure(fig.number)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection\n",
    "\n",
    "Let's use our package's analyze_anomalies function to detect anomalies in the audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our package's function to detect anomalies\n",
    "anomaly_results = analyze_anomalies(audio_data, sample_rate, title_prefix=\"Sample Audio\")\n",
    "\n",
    "# Display the figures\n",
    "for fig_name, fig in anomaly_results['figures'].items():\n",
    "    plt.figure(fig.number)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silence Detection\n",
    "\n",
    "Let's use our package's time domain analysis to detect silent regions in the audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our package's function to detect silent regions\n",
    "silence_regions = time_domain_results['silent_regions']\n",
    "\n",
    "# Print silent regions\n",
    "print(\"Non-silent regions:\")\n",
    "for i, (start, end) in enumerate(silence_regions):\n",
    "    print(f\"Region {i+1}: {start:.2f}s - {end:.2f}s (duration: {end-start:.2f}s)\")\n",
    "\n",
    "# Plot waveform with non-silent regions highlighted\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(audio_data, sr=sample_rate, alpha=0.5)\n",
    "\n",
    "# Highlight non-silent regions\n",
    "for start, end in silence_regions:\n",
    "    plt.axvspan(start, end, color='red', alpha=0.3)\n",
    "\n",
    "plt.title('Waveform with Non-Silent Regions Highlighted')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've performed a basic exploratory data analysis of an audio file using the CTC-SpeechRefinement package. We've examined its waveform, computed descriptive statistics, and analyzed it in both the time and frequency domains using the package's built-in functions. We've also analyzed pitch and timbre characteristics and detected anomalies in the audio.\n",
    "\n",
    "This analysis provides a good starting point for understanding the characteristics of the audio data, which can be useful for preprocessing and feature extraction for speech recognition tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
