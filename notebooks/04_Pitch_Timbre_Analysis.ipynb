{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitch and Timbre Analysis\n",
    "\n",
    "This notebook demonstrates how to perform pitch and timbre analysis on audio files using the CTC-SpeechRefinement package. We'll explore various techniques for analyzing pitch, harmonics, and timbral characteristics of audio signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the project root to the Python path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import Audio, display\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Import from the project\n",
    "from ctc_speech_refinement.core.preprocessing.audio import load_audio\n",
    "from ctc_speech_refinement.core.eda.pitch_timbre import analyze_pitch_timbre\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Audio Data\n",
    "\n",
    "Let's load an audio file and examine its basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to an audio file\n",
    "audio_file = \"../data/speech2text/input/test1_01.wav\"  # Path to the audio file\n",
    "\n",
    "# Load the audio file using our package's function\n",
    "audio_data, sample_rate = load_audio(audio_file)\n",
    "\n",
    "# Print basic information\n",
    "print(f\"Audio file: {audio_file}\")\n",
    "print(f\"Sample rate: {sample_rate} Hz\")\n",
    "print(f\"Duration: {len(audio_data) / sample_rate:.2f} seconds\")\n",
    "print(f\"Number of samples: {len(audio_data)}\")\n",
    "\n",
    "# Play the audio\n",
    "display(Audio(audio_data, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Pitch and Timbre Analysis\n",
    "\n",
    "Let's use our package's analyze_pitch_timbre function to perform a comprehensive analysis of the pitch and timbre characteristics of the audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our package's function to analyze pitch and timbre features\n",
    "pitch_timbre_results = analyze_pitch_timbre(audio_data, sample_rate, title_prefix=\"Sample Audio\")\n",
    "\n",
    "# Display the pitch statistics\n",
    "print(\"\\nPitch Statistics:\")\n",
    "for stat, value in pitch_timbre_results['pitch_stats'].items():\n",
    "    print(f\"{stat}: {value}\")\n",
    "\n",
    "# Display the MFCC statistics\n",
    "print(\"\\nMFCC Statistics:\")\n",
    "for stat, value in pitch_timbre_results['mfcc_stats'].items():\n",
    "    print(f\"{stat}: {value}\")\n",
    "\n",
    "# Display the figures\n",
    "for fig_name, fig in pitch_timbre_results['figures'].items():\n",
    "    plt.figure(fig.number)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Pitch Analysis\n",
    "\n",
    "Now let's explore pitch analysis in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fundamental Frequency (F0) Estimation\n",
    "\n",
    "The fundamental frequency (F0) is the lowest frequency of a periodic waveform. In speech, it corresponds to the perceived pitch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pitch using librosa's piptrack\n",
    "pitches, magnitudes = librosa.piptrack(y=audio_data, sr=sample_rate, n_fft=2048, hop_length=512)\n",
    "pitch_times = librosa.times_like(pitches[0], sr=sample_rate, hop_length=512)\n",
    "\n",
    "# Extract the pitch with highest magnitude at each time\n",
    "pitch = []\n",
    "for t in range(pitches.shape[1]):\n",
    "    index = magnitudes[:, t].argmax()\n",
    "    pitch.append(pitches[index, t])\n",
    "\n",
    "# Filter out zero values (silence or unvoiced segments)\n",
    "pitch_times_filtered = []\n",
    "pitch_filtered = []\n",
    "for i, p in enumerate(pitch):\n",
    "    if p > 0:\n",
    "        pitch_filtered.append(p)\n",
    "        pitch_times_filtered.append(pitch_times[i])\n",
    "\n",
    "# Plot pitch\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.semilogy(pitch_times_filtered, pitch_filtered)\n",
    "plt.title('Pitch (Fundamental Frequency)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pitch Distribution\n",
    "\n",
    "Let's analyze the distribution of pitch values to understand the range and variability of pitch in the audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pitch distribution\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.histplot(pitch_filtered, kde=True)\n",
    "plt.axvline(np.mean(pitch_filtered), color='r', linestyle='--', label=f'Mean: {np.mean(pitch_filtered):.2f} Hz')\n",
    "plt.axvline(np.median(pitch_filtered), color='g', linestyle='--', label=f'Median: {np.median(pitch_filtered):.2f} Hz')\n",
    "plt.title('Pitch Distribution')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Harmonic Components\n",
    "\n",
    "Let's analyze the harmonic components of the audio using the harmonic-percussive source separation technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate harmonic and percussive components\n",
    "harmonic, percussive = librosa.effects.hpss(audio_data)\n",
    "\n",
    "# Play the harmonic component\n",
    "print(\"Harmonic Component:\")\n",
    "display(Audio(harmonic, rate=sample_rate))\n",
    "\n",
    "# Play the percussive component\n",
    "print(\"Percussive Component:\")\n",
    "display(Audio(percussive, rate=sample_rate))\n",
    "\n",
    "# Plot waveforms\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "librosa.display.waveshow(audio_data, sr=sample_rate, ax=ax1)\n",
    "ax1.set_title('Original Waveform')\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "\n",
    "librosa.display.waveshow(harmonic, sr=sample_rate, ax=ax2)\n",
    "ax2.set_title('Harmonic Component')\n",
    "ax2.set_xlabel('')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "\n",
    "librosa.display.waveshow(percussive, sr=sample_rate, ax=ax3)\n",
    "ax3.set_title('Percussive Component')\n",
    "ax3.set_xlabel('Time (s)')\n",
    "ax3.set_ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Timbre Analysis\n",
    "\n",
    "Now let's explore timbre analysis in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Mel-Frequency Cepstral Coefficients (MFCCs)\n",
    "\n",
    "MFCCs are coefficients that collectively make up an MFC (Mel-frequency cepstrum), which is a representation of the short-term power spectrum of a sound. They are widely used in speech recognition and music information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MFCCs\n",
    "mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13, n_fft=2048, hop_length=512)\n",
    "\n",
    "# Plot MFCCs\n",
    "plt.figure(figsize=(14, 7))\n",
    "librosa.display.specshow(mfccs, sr=sample_rate, x_axis='time', hop_length=512)\n",
    "plt.colorbar()\n",
    "plt.title('MFCCs')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Delta and Delta-Delta MFCCs\n",
    "\n",
    "Delta and delta-delta (acceleration) coefficients are computed from the MFCCs to capture the dynamics of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute delta and delta-delta MFCCs\n",
    "delta_mfccs = librosa.feature.delta(mfccs)\n",
    "delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "\n",
    "# Plot delta MFCCs\n",
    "plt.figure(figsize=(14, 7))\n",
    "librosa.display.specshow(delta_mfccs, sr=sample_rate, x_axis='time', hop_length=512)\n",
    "plt.colorbar()\n",
    "plt.title('Delta MFCCs')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot delta-delta MFCCs\n",
    "plt.figure(figsize=(14, 7))\n",
    "librosa.display.specshow(delta2_mfccs, sr=sample_rate, x_axis='time', hop_length=512)\n",
    "plt.colorbar()\n",
    "plt.title('Delta-Delta MFCCs')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Chromagram\n",
    "\n",
    "A chromagram represents the distribution of energy along the 12 pitch classes (C, C#, D, etc.). It is useful for analyzing the harmonic content of music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute chromagram\n",
    "chroma = librosa.feature.chroma_stft(y=audio_data, sr=sample_rate, n_fft=2048, hop_length=512)\n",
    "\n",
    "# Plot chromagram\n",
    "plt.figure(figsize=(14, 7))\n",
    "librosa.display.specshow(chroma, sr=sample_rate, x_axis='time', y_axis='chroma', hop_length=512)\n",
    "plt.colorbar()\n",
    "plt.title('Chromagram')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've performed a comprehensive pitch and timbre analysis of an audio file using the CTC-SpeechRefinement package. We've examined various features including fundamental frequency, harmonic components, MFCCs, delta MFCCs, and chromagram. These features provide valuable insights into the pitch and timbral characteristics of the audio signal, which can be useful for speech recognition tasks, speaker identification, and other audio processing applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
