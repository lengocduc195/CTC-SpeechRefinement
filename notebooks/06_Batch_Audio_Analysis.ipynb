{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Audio Analysis\n",
    "\n",
    "This notebook demonstrates how to perform batch analysis on multiple audio files using the CTC-SpeechRefinement package. We'll explore techniques for analyzing a collection of audio files, comparing their characteristics, and generating summary reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the project root to the Python path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import Audio, display, HTML\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Import from the project\n",
    "from ctc_speech_refinement.core.preprocessing.audio import load_audio\n",
    "from ctc_speech_refinement.core.eda.descriptive_stats import analyze_descriptive_stats, batch_analyze_descriptive_stats\n",
    "from ctc_speech_refinement.core.eda.time_domain import analyze_time_domain, batch_analyze_time_domain\n",
    "from ctc_speech_refinement.core.eda.frequency_domain import analyze_frequency_domain, batch_analyze_frequency_domain\n",
    "from ctc_speech_refinement.core.eda.pitch_timbre import analyze_pitch_timbre, batch_analyze_pitch_timbre\n",
    "from ctc_speech_refinement.core.eda.anomaly_detection import analyze_anomalies, batch_analyze_anomalies\n",
    "from ctc_speech_refinement.core.utils.file_utils import get_audio_files\n",
    "from ctc_speech_refinement.core.eda.audio_eda import analyze_directory\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Multiple Audio Files\n",
    "\n",
    "Let's load multiple audio files from a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the directory containing audio files\n",
    "audio_dir = \"../data/speech2text/input\"  # Path to the audio directory\n",
    "\n",
    "# Get list of audio files\n",
    "audio_files = get_audio_files(audio_dir)\n",
    "print(f\"Found {len(audio_files)} audio files in {audio_dir}\")\n",
    "for file in audio_files:\n",
    "    print(f\"- {file}\")\n",
    "\n",
    "# Load audio files\n",
    "audio_data_dict = {}\n",
    "for file in audio_files:\n",
    "    audio_data, sample_rate = load_audio(file)\n",
    "    audio_data_dict[file] = (audio_data, sample_rate)\n",
    "    \n",
    "print(f\"\\nLoaded {len(audio_data_dict)} audio files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Information\n",
    "\n",
    "Let's display basic information about each audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with basic information\n",
    "basic_info = []\n",
    "for file, (audio_data, sample_rate) in audio_data_dict.items():\n",
    "    duration = len(audio_data) / sample_rate\n",
    "    basic_info.append({\n",
    "        'File': os.path.basename(file),\n",
    "        'Sample Rate (Hz)': sample_rate,\n",
    "        'Duration (s)': duration,\n",
    "        'Num Samples': len(audio_data),\n",
    "        'Mean Amplitude': np.mean(audio_data),\n",
    "        'RMS': np.sqrt(np.mean(np.square(audio_data)))\n",
    "    })\n",
    "    \n",
    "basic_info_df = pd.DataFrame(basic_info)\n",
    "basic_info_df.set_index('File', inplace=True)\n",
    "basic_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch Descriptive Statistics Analysis\n",
    "\n",
    "Let's perform descriptive statistics analysis on all audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform batch descriptive statistics analysis\n",
    "descriptive_stats_results = batch_analyze_descriptive_stats(audio_data_dict)\n",
    "\n",
    "# Create a DataFrame with descriptive statistics\n",
    "stats_df = pd.DataFrame()\n",
    "for file, results in descriptive_stats_results.items():\n",
    "    file_name = os.path.basename(file)\n",
    "    stats = results['stats']\n",
    "    stats_df[file_name] = pd.Series(stats)\n",
    "    \n",
    "# Display the statistics\n",
    "stats_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Waveforms\n",
    "\n",
    "Let's compare the waveforms of all audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot waveforms of all audio files\n",
    "n_files = len(audio_data_dict)\n",
    "fig, axes = plt.subplots(n_files, 1, figsize=(14, 4 * n_files))\n",
    "if n_files == 1:\n",
    "    axes = [axes]\n",
    "    \n",
    "for i, (file, (audio_data, sample_rate)) in enumerate(audio_data_dict.items()):\n",
    "    file_name = os.path.basename(file)\n",
    "    librosa.display.waveshow(audio_data, sr=sample_rate, ax=axes[i])\n",
    "    axes[i].set_title(f'Waveform: {file_name}')\n",
    "    axes[i].set_xlabel('Time (s)')\n",
    "    axes[i].set_ylabel('Amplitude')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Spectrograms\n",
    "\n",
    "Let's compare the spectrograms of all audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spectrograms of all audio files\n",
    "n_files = len(audio_data_dict)\n",
    "fig, axes = plt.subplots(n_files, 1, figsize=(14, 5 * n_files))\n",
    "if n_files == 1:\n",
    "    axes = [axes]\n",
    "    \n",
    "for i, (file, (audio_data, sample_rate)) in enumerate(audio_data_dict.items()):\n",
    "    file_name = os.path.basename(file)\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio_data)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, sr=sample_rate, x_axis='time', y_axis='log', ax=axes[i])\n",
    "    fig.colorbar(img, ax=axes[i], format='%+2.0f dB')\n",
    "    axes[i].set_title(f'Spectrogram: {file_name}')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Time Domain Analysis\n",
    "\n",
    "Let's perform time domain analysis on all audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform batch time domain analysis\n",
    "time_domain_results = batch_analyze_time_domain(audio_data_dict)\n",
    "\n",
    "# Display silent regions for each file\n",
    "for file, results in time_domain_results.items():\n",
    "    file_name = os.path.basename(file)\n",
    "    silent_regions = results['silent_regions']\n",
    "    print(f\"\\nSilent regions in {file_name}:\")\n",
    "    for i, (start, end) in enumerate(silent_regions):\n",
    "        print(f\"Region {i+1}: {start:.2f}s - {end:.2f}s (duration: {end-start:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Frequency Domain Analysis\n",
    "\n",
    "Let's perform frequency domain analysis on all audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform batch frequency domain analysis\n",
    "frequency_domain_results = batch_analyze_frequency_domain(audio_data_dict)\n",
    "\n",
    "# Create a DataFrame with spectral features\n",
    "spectral_df = pd.DataFrame()\n",
    "for file, results in frequency_domain_results.items():\n",
    "    file_name = os.path.basename(file)\n",
    "    spectral_features = results['spectral_features']\n",
    "    spectral_df[file_name] = pd.Series(spectral_features)\n",
    "    \n",
    "# Display the spectral features\n",
    "spectral_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch Pitch and Timbre Analysis\n",
    "\n",
    "Let's perform pitch and timbre analysis on all audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform batch pitch and timbre analysis\n",
    "pitch_timbre_results = batch_analyze_pitch_timbre(audio_data_dict)\n",
    "\n",
    "# Create DataFrames with pitch and MFCC statistics\n",
    "pitch_df = pd.DataFrame()\n",
    "mfcc_df = pd.DataFrame()\n",
    "for file, results in pitch_timbre_results.items():\n",
    "    file_name = os.path.basename(file)\n",
    "    pitch_stats = results['pitch_stats']\n",
    "    mfcc_stats = results['mfcc_stats']\n",
    "    pitch_df[file_name] = pd.Series(pitch_stats)\n",
    "    mfcc_df[file_name] = pd.Series(mfcc_stats)\n",
    "    \n",
    "# Display the pitch statistics\n",
    "print(\"Pitch Statistics:\")\n",
    "pitch_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the MFCC statistics\n",
    "print(\"MFCC Statistics:\")\n",
    "mfcc_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Batch Anomaly Detection\n",
    "\n",
    "Let's perform anomaly detection on all audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform batch anomaly detection\n",
    "anomaly_results = batch_analyze_anomalies(audio_data_dict)\n",
    "\n",
    "# Display anomalies for each file\n",
    "for file, results in anomaly_results.items():\n",
    "    file_name = os.path.basename(file)\n",
    "    amplitude_anomalies = results['amplitude_anomalies']\n",
    "    spectral_anomalies = results['spectral_anomalies']\n",
    "    \n",
    "    print(f\"\\nAnomalies in {file_name}:\")\n",
    "    \n",
    "    print(\"Amplitude Anomalies:\")\n",
    "    for i, (start, end) in enumerate(amplitude_anomalies):\n",
    "        print(f\"Anomaly {i+1}: {start:.2f}s - {end:.2f}s (duration: {end-start:.2f}s)\")\n",
    "    \n",
    "    print(\"Spectral Anomalies:\")\n",
    "    for i, (start, end) in enumerate(spectral_anomalies):\n",
    "        print(f\"Anomaly {i+1}: {start:.2f}s - {end:.2f}s (duration: {end-start:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Generate Summary Report\n",
    "\n",
    "Let's generate a summary report of the batch analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary DataFrame\n",
    "summary_df = pd.DataFrame()\n",
    "\n",
    "# Add basic information\n",
    "summary_df['Duration (s)'] = basic_info_df['Duration (s)']\n",
    "summary_df['Sample Rate (Hz)'] = basic_info_df['Sample Rate (Hz)']\n",
    "summary_df['RMS'] = basic_info_df['RMS']\n",
    "\n",
    "# Add key statistics\n",
    "for file_name in stats_df.columns:\n",
    "    summary_df.loc[file_name, 'Mean Amplitude'] = stats_df[file_name]['mean']\n",
    "    summary_df.loc[file_name, 'Std Dev'] = stats_df[file_name]['std']\n",
    "    summary_df.loc[file_name, 'Dynamic Range'] = stats_df[file_name]['dynamic_range']\n",
    "    summary_df.loc[file_name, 'Zero Crossings'] = stats_df[file_name]['zero_crossings']\n",
    "\n",
    "# Add key spectral features\n",
    "for file_name in spectral_df.columns:\n",
    "    summary_df.loc[file_name, 'Spectral Centroid (Hz)'] = spectral_df[file_name]['spectral_centroid_mean']\n",
    "    summary_df.loc[file_name, 'Spectral Bandwidth (Hz)'] = spectral_df[file_name]['spectral_bandwidth_mean']\n",
    "    summary_df.loc[file_name, 'Spectral Flatness'] = spectral_df[file_name]['spectral_flatness_mean']\n",
    "\n",
    "# Add key pitch statistics\n",
    "for file_name in pitch_df.columns:\n",
    "    summary_df.loc[file_name, 'Mean Pitch (Hz)'] = pitch_df[file_name]['mean_pitch']\n",
    "    summary_df.loc[file_name, 'Pitch Range (Hz)'] = pitch_df[file_name]['pitch_range']\n",
    "\n",
    "# Add anomaly counts\n",
    "for file, results in anomaly_results.items():\n",
    "    file_name = os.path.basename(file)\n",
    "    summary_df.loc[file_name, 'Amplitude Anomalies'] = len(results['amplitude_anomalies'])\n",
    "    summary_df.loc[file_name, 'Spectral Anomalies'] = len(results['spectral_anomalies'])\n",
    "\n",
    "# Display the summary report\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualize Summary Statistics\n",
    "\n",
    "Let's visualize some key statistics across all audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot key statistics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Duration\n",
    "summary_df['Duration (s)'].plot(kind='bar', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Duration (s)')\n",
    "axes[0, 0].set_ylabel('Seconds')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# RMS\n",
    "summary_df['RMS'].plot(kind='bar', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('RMS Amplitude')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Spectral Centroid\n",
    "summary_df['Spectral Centroid (Hz)'].plot(kind='bar', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Spectral Centroid (Hz)')\n",
    "axes[1, 0].set_ylabel('Frequency (Hz)')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Mean Pitch\n",
    "summary_df['Mean Pitch (Hz)'].plot(kind='bar', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Mean Pitch (Hz)')\n",
    "axes[1, 1].set_ylabel('Frequency (Hz)')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Using the analyze_directory Function\n",
    "\n",
    "Let's use the analyze_directory function to perform a comprehensive analysis of all audio files in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directory for results\n",
    "output_dir = \"../data/speech2text/eda_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Perform comprehensive analysis of all audio files in the directory\n",
    "results = analyze_directory(\n",
    "    audio_dir,\n",
    "    output_dir=output_dir,\n",
    "    normalize=True,\n",
    "    remove_silence=False\n",
    ")\n",
    "\n",
    "print(f\"Analysis completed. Results saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've performed a comprehensive batch analysis of multiple audio files using the CTC-SpeechRefinement package. We've explored various techniques for analyzing a collection of audio files, comparing their characteristics, and generating summary reports. This approach is useful for understanding the overall characteristics of a dataset, identifying outliers, and ensuring consistency across multiple recordings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
